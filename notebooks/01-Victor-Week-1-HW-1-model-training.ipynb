{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ebb0a6-9f22-4907-b611-d6c8ff6405fd",
   "metadata": {},
   "source": [
    "# DataTalks - MLOps ZoomCamp - Week 1 - HW 1\n",
    "\n",
    "The goal of the homework is to train a simple model for predicting the duration of a ride.\n",
    "\n",
    "Link to homework: [https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/01-intro/homework.md](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/01-intro/homework.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6ec11-2f2d-4c02-a3e4-7836c9097487",
   "metadata": {},
   "source": [
    "## 1. Initializing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784c89dc-97d9-4ecc-83d0-c28972ace4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the set of Python packages needed for the analysis\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from typing import Optional\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4b537-250e-4334-8343-b9b958350dfd",
   "metadata": {},
   "source": [
    "## 2. Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864a6f5-de01-4b6a-b531-cd4df2b48c2e",
   "metadata": {},
   "source": [
    "We can now download the data from the NYC website: [https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e1d61d-6dd8-4846-9db4-045568cfc892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Defining the URL of the data\n",
    "# NOTE: The current data uses AWS cloudfront for managing the dataset.\n",
    "\n",
    "\n",
    "def download_dataset(year: str, month: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to download the dataset from the\n",
    "    ``NYC Taxi & Limousine Commission`` website.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    year : str\n",
    "        Year, for which to download the dataset.\n",
    "\n",
    "    month : str\n",
    "        Month, for which to download the dataset.\n",
    "        The variable must contain 2 digits, e.g.\n",
    "        'February' would be represented as '02'.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    nyc_dataset : pandas.DataFrame\n",
    "        Dataset of the NYC Taxi & Limousine trip data.\n",
    "    \"\"\"\n",
    "    # Checking input data\n",
    "    # `year` - Type check\n",
    "    year_type_arr = (str, int)\n",
    "    if not isinstance(year, year_type_arr):\n",
    "        msg = \"`year` ({}) is not of the correct data type ({})\"\n",
    "        msg = msg.format(type(year), year_type_arr)\n",
    "        raise TypeError(msg)\n",
    "    # `month` - Type check\n",
    "    month_type_arr = (str,)\n",
    "    if not isinstance(month, month_type_arr):\n",
    "        msg = \"`month` ({}) is not of the correct data type ({})\"\n",
    "        msg = msg.format(type(month), month_type_arr)\n",
    "        raise TypeError(msg)\n",
    "    # `month` - Lenght check\n",
    "    if len(month) != 2:\n",
    "        msg = \"`month` must have two digits and only has {}\"\n",
    "        msg = msg.format(len(month))\n",
    "        raise ValueError(msg)\n",
    "    #\n",
    "    # Base URL\n",
    "    dataset_url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_{year}-{month}.parquet\"\n",
    "\n",
    "    logger.info(f\">> Reading '{dataset_url}'\")\n",
    "\n",
    "    return pd.read_parquet(dataset_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361e3814-5f13-4a5f-a9fb-d9b3dacdd6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:>> Reading 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-01.parquet'\n",
      "INFO:__main__:>> Reading 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet'\n"
     ]
    }
   ],
   "source": [
    "# Dataset for '2023' - 'February\n",
    "dataset_jan = download_dataset(year=\"2021\", month=\"01\")\n",
    "\n",
    "# Dataset for '2023' - 'February\n",
    "dataset_feb = download_dataset(year=\"2021\", month=\"02\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6426d18e-c3a0-4762-a60c-341747b5fc6a",
   "metadata": {},
   "source": [
    "## 3. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574676ce-cfb3-49cc-a325-8bb42bb900f6",
   "metadata": {},
   "source": [
    "### 3.1 Describing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a66c0-3dbf-4da3-bc2b-9852495cbeeb",
   "metadata": {},
   "source": [
    "We can now visualize both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c776aeee-7469-46f9-a10d-433e6c4849f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID   \n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00           NaN  \\\n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00           NaN   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00           NaN   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26           NaN   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00009  \n",
       "1           NaN    None                 B00009  \n",
       "2           NaN    None                 B00013  \n",
       "3          72.0    None                 B00037  \n",
       "4          61.0    None                 B00037  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b38a584d-4bd8-461f-84f8-4a957814bff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-02-01 00:01:00</td>\n",
       "      <td>2021-02-01 01:33:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:55:40</td>\n",
       "      <td>2021-02-01 01:06:20</td>\n",
       "      <td>173.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:14:03</td>\n",
       "      <td>2021-02-01 00:28:37</td>\n",
       "      <td>173.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:27:48</td>\n",
       "      <td>2021-02-01 00:35:45</td>\n",
       "      <td>82.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-02-01 00:12:50</td>\n",
       "      <td>2021-02-01 00:26:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID   \n",
       "0               B00013 2021-02-01 00:01:00 2021-02-01 01:33:00           NaN  \\\n",
       "1      B00021          2021-02-01 00:55:40 2021-02-01 01:06:20         173.0   \n",
       "2      B00021          2021-02-01 00:14:03 2021-02-01 00:28:37         173.0   \n",
       "3      B00021          2021-02-01 00:27:48 2021-02-01 00:35:45          82.0   \n",
       "4               B00037 2021-02-01 00:12:50 2021-02-01 00:26:38           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00014  \n",
       "1          82.0    None        B00021           \n",
       "2          56.0    None        B00021           \n",
       "3         129.0    None        B00021           \n",
       "4         225.0    None                 B00037  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_feb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2135e6-622c-4a22-8438-3219b6cf69a5",
   "metadata": {},
   "source": [
    "Similarly, we can now describe both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232cd9da-afee-4adc-96cc-228436477ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:>> There are `1154112` records for the 'January' dataset\n",
      "INFO:__main__:>> There are `1037692` records for the 'February' dataset\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\">> There are `{len(dataset_jan)}` records for the 'January' dataset\")\n",
    "\n",
    "logger.info(f\">> There are `{len(dataset_feb)}` records for the 'February' dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9acf749-af31-4dae-ae99-dc72f65dc101",
   "metadata": {},
   "source": [
    "### 3.2 Computing the trip duration\n",
    "\n",
    "We can now compute the `duration` variable in *minutes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2bfeeb-f6cb-40be-aac3-951bbda52b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_trip_duration(dataset: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Function to calculate the trip duration for a set of pickup and dropoff times.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    dataset : pandas.DataFrame\n",
    "        Dataset containing the trip data for pickup and drop off times.\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    trip_duration : pd.Series\n",
    "        Series corresponding to the trip duration in ``minutes``.\n",
    "    \"\"\"\n",
    "    # Defining column names\n",
    "    pickup_colname = \"pickup_datetime\"\n",
    "    dropoff_colname = \"dropOff_datetime\"\n",
    "\n",
    "    # Calculating trip duration in minutes\n",
    "\n",
    "    return (\n",
    "        pd.to_datetime(dataset[dropoff_colname])\n",
    "        - pd.to_datetime(dataset[pickup_colname])\n",
    "    ).dt.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0fca8-8441-4a75-b928-d07658994755",
   "metadata": {},
   "source": [
    "We can now run the function for each of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d52037-3f15-431a-a9e2-5bfafb484f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# January\n",
    "dataset_jan[\"duration\"] = calculate_trip_duration(dataset_jan)\n",
    "\n",
    "# February\n",
    "dataset_feb[\"duration\"] = calculate_trip_duration(dataset_feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ade4ae-19e9-43aa-8986-72e7f5cf938e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:>> The average trip duration in 'January' is '19.17' minutes\n",
      "INFO:__main__:>> The average trip duration in 'February' is '20.71' minutes\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\">> The average trip duration in 'January' is '{dataset_jan['duration'].mean():0.2f}' minutes\")\n",
    "\n",
    "logger.info(f\">> The average trip duration in 'February' is '{dataset_feb['duration'].mean():0.2f}' minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ab7b2-820b-4a4e-a589-ee854bf0d048",
   "metadata": {},
   "source": [
    "## 4. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b94e8-2fe8-41f8-beb3-64808c1f55d4",
   "metadata": {},
   "source": [
    "We are only interested in the trips with durations between `1` and `60` minutes (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857e35d1-4214-47c8-96d3-a8edb945da05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:There are `1109826` number of trips between [0,60] minutes in 'January'. (# of records dropped: 44286)\n",
      "INFO:__main__:There are `990113` number of trips between [0,60] minutes in 'February'. (# of records dropped: 47579)\n"
     ]
    }
   ],
   "source": [
    "# January\n",
    "dataset_jan_filtered = dataset_jan.loc[\n",
    "    dataset_jan[\"duration\"].between(1, 60, inclusive=\"both\")\n",
    "]\n",
    "\n",
    "logger.info(\n",
    "    f\"There are `{len(dataset_jan_filtered)}` number of trips between [0,60] minutes in 'January'. (# of records dropped: {len(dataset_jan) - len(dataset_jan_filtered)})\"\n",
    ")\n",
    "\n",
    "# February\n",
    "\n",
    "dataset_feb_filtered = dataset_feb.loc[\n",
    "    dataset_feb[\"duration\"].between(1, 60, inclusive=\"both\")\n",
    "]\n",
    "\n",
    "logger.info(\n",
    "    f\"There are `{len(dataset_feb_filtered)}` number of trips between [0,60] minutes in 'February'. (# of records dropped: {len(dataset_feb) - len(dataset_feb_filtered)})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11dc787-a774-4309-b39e-e4f218e56798",
   "metadata": {},
   "source": [
    "## 5. Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37922921-67c2-4989-9f15-d91740219974",
   "metadata": {},
   "source": [
    "In order to create the necessary features for our model, we first need to do some data cleaning:\n",
    "\n",
    "1. Replace the missing values of the pickup and dropoff location IDs with `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc5368f-ce41-48ef-8b2d-90120140d032",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:>> There is a total of '83.53%' of missing values - Pickup IDs - January\n",
      "INFO:__main__:>> There is a total of '13.33%' of missing values - DropOff IDs - January\n"
     ]
    }
   ],
   "source": [
    "# Defining column names\n",
    "pickup_id_colname = \"PUlocationID\"\n",
    "dropoff_id_colname = \"DOlocationID\"\n",
    "\n",
    "# Number of records with missing values - January\n",
    "missing_data_jan_pickup_id_frac = 100 * dataset_jan_filtered[pickup_id_colname].isna().sum()/len(dataset_jan_filtered[pickup_id_colname])\n",
    "missing_data_jan_dropoff_id_frac = 100 * dataset_jan_filtered[dropoff_id_colname].isna().sum()/len(dataset_jan_filtered[dropoff_id_colname])\n",
    "\n",
    "logger.info(f\">> There is a total of '{missing_data_jan_pickup_id_frac:.2f}%' of missing values - Pickup IDs - January\")\n",
    "logger.info(f\">> There is a total of '{missing_data_jan_dropoff_id_frac:.2f}%' of missing values - DropOff IDs - January\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58923b28-9eba-4eb2-8339-e0a073c17a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replacing missing values with '-1'\n",
    "for colname in [pickup_id_colname, dropoff_id_colname]:\n",
    "    dataset_jan_filtered.loc[:, colname] = dataset_jan_filtered[colname].fillna(-1).astype(int)\n",
    "    dataset_feb_filtered.loc[:, colname] = dataset_feb_filtered[colname].fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42771b7a-472d-4dd7-9847-2c92942345a6",
   "metadata": {},
   "source": [
    "## 6. One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f27bb-fbc2-4279-b8f4-a748fa853219",
   "metadata": {},
   "source": [
    "We need to convert the categorical data into one-hot encoding using a *dictionary  vectorizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81170b99-fb69-4cac-be2c-b23377b06fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to use for the categorical columns\n",
    "categorical_colnames = [pickup_id_colname, dropoff_id_colname]\n",
    "\n",
    "# Turning the categorical variables into strings for the dictionary vectorizer\n",
    "dataset_jan_filtered.loc[:, categorical_colnames] = dataset_jan_filtered[categorical_colnames].astype(str)\n",
    "\n",
    "# Creating train and predictor variables for each dataset\n",
    "train_dict_jan = dataset_jan_filtered[categorical_colnames].to_dict(orient=\"records\")\n",
    "train_dict_feb = dataset_feb_filtered[categorical_colnames].to_dict(orient=\"records\")\n",
    "\n",
    "# Initializing vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# And computing the one-hot encoding\n",
    "X_train = dv.fit_transform(train_dict_jan)\n",
    "\n",
    "# And now the variable that we can to predict on\n",
    "y_train = dataset_jan_filtered[\"duration\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d71fdbe-9d24-4161-b961-27030001d813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:The shape of the training features: '(1109826, 525)' - January\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"The shape of the training features: '{X_train.shape}' - January\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029f8ae-0a9d-405e-8d28-046469f9f1b1",
   "metadata": {},
   "source": [
    "We now have the necessary ingredients to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a1c62-d704-4f61-89f4-6798bc2fca11",
   "metadata": {},
   "source": [
    "## 7. Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a563e-aafa-4d99-bbbe-f7dd4d2739c6",
   "metadata": {},
   "source": [
    "We can now train a linear regression model with the data from **January**. We can then use\n",
    "that model to validate it with the data from **February**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c3e5d40-bbd5-4a90-9696-e85edb0975c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Training a linear model\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f26d7-5cd8-4459-a2d2-bc2e0f695de9",
   "metadata": {},
   "source": [
    "We can now calculate the `RMSE` (root-mean-squared-error) between the actual `duration` of the trip to\n",
    "the inferred one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3492797-70a8-44b9-94fd-cab535ba9511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:The RMSE between the 'real' and 'predicted' trip duration is: 10.53\n"
     ]
    }
   ],
   "source": [
    "# Predicted 'duration' using the Linear regression model\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "# Calculating the RMSE of the data\n",
    "rmse = mean_squared_error(y_train, y_pred, squared=False)\n",
    "\n",
    "logger.info(f\"The RMSE between the 'real' and 'predicted' trip duration is: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157d2c3-9bca-48a8-877e-15d080e997fe",
   "metadata": {},
   "source": [
    "## 8. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d09388-8a13-4b25-ab2f-8b8fe6c48651",
   "metadata": {},
   "source": [
    "The next step is to evaluate the model on a brand new dataset, i.e. a dataset that the model hasn't\n",
    "been trained on. For example, we'll validate the model using the dataset from *February*.\n",
    "\n",
    "To do this, we'll need to perform the same set of data preparation tasks that we've done for the dataset\n",
    "from *January*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f42345ec-043b-4060-aa3d-4a745b8e0736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preparation(\n",
    "    month: str,\n",
    "    year: str,\n",
    "    min_duration: Optional[int] = 1,\n",
    "    max_duration: Optional[int] = 60,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to prepare a dataset. This function will perform the\n",
    "    data cleaning steps, as well as any data type casting, etc.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    month : str\n",
    "        Month, for which to download the dataset.\n",
    "        The variable must contain 2 digits, e.g.\n",
    "        'February' would be represented as '02'.\n",
    "\n",
    "    year : str\n",
    "        Year, for which to download the dataset.\n",
    "\n",
    "    min_duration : int, optional\n",
    "        Minimum number of minutes that a trip lasts.\n",
    "        This variable is set to ``1`` by default.\n",
    "\n",
    "    max_duration : int, optional\n",
    "        Maximum number of minutes that a trip lasts.\n",
    "        This variable is set to ``60`` by default.\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    dataset_processed : pandas.DataFrame\n",
    "        Dataset after having gone through the data cleaning and\n",
    "        data processing steps.\n",
    "    \"\"\"\n",
    "    # 1. Reading in the dataset\n",
    "    raw_dataset = download_dataset(month=month, year=year)\n",
    "\n",
    "    # 2. Computing trip duration\n",
    "    duration_colname = \"duration\"\n",
    "    raw_dataset[duration_colname] = calculate_trip_duration(\n",
    "        dataset=raw_dataset\n",
    "    )\n",
    "\n",
    "    # 3. Filtering the trips that lasted within 1 minute and 60 mins.\n",
    "    dataset = raw_dataset.loc[\n",
    "        raw_dataset[duration_colname].between(\n",
    "            min_duration, max_duration, inclusive=\"both\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # 4. Handle missing values for the pickup ID and dropoff ID.\n",
    "    pickup_id_colname = \"PUlocationID\"\n",
    "    dropoff_id_colname = \"DOlocationID\"\n",
    "    fill_value = -1\n",
    "\n",
    "    categorical_cols = [pickup_id_colname, dropoff_id_colname]\n",
    "\n",
    "    dataset.loc[:, categorical_cols] = (\n",
    "        dataset[categorical_cols].fillna(fill_value).astype(int).astype(str)\n",
    "    )\n",
    "\n",
    "    return dataset.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2214543-13bd-42f3-b068-cbc1a6c75ca0",
   "metadata": {},
   "source": [
    "In order to validate our results, we will read the dataset from `2023-02` and pass the dataset\n",
    "through the data processing pipeline using the function `data_preparation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "611adf77-74c6-4fa6-b578-4dd4c2f19417",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:>> Reading 'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet'\n"
     ]
    }
   ],
   "source": [
    "val_dataset = data_preparation(month=\"02\", year=\"2021\", min_duration=1, max_duration=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e5ed867-10b9-4396-8227-bac409baab0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:55:40</td>\n",
       "      <td>2021-02-01 01:06:20</td>\n",
       "      <td>173</td>\n",
       "      <td>82</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "      <td>10.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:14:03</td>\n",
       "      <td>2021-02-01 00:28:37</td>\n",
       "      <td>173</td>\n",
       "      <td>56</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "      <td>14.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:27:48</td>\n",
       "      <td>2021-02-01 00:35:45</td>\n",
       "      <td>82</td>\n",
       "      <td>129</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "      <td>7.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-02-01 00:12:50</td>\n",
       "      <td>2021-02-01 00:26:38</td>\n",
       "      <td>-1</td>\n",
       "      <td>225</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "      <td>13.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-02-01 00:00:37</td>\n",
       "      <td>2021-02-01 00:09:35</td>\n",
       "      <td>-1</td>\n",
       "      <td>61</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "      <td>8.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime PUlocationID   \n",
       "0      B00021          2021-02-01 00:55:40 2021-02-01 01:06:20          173  \\\n",
       "1      B00021          2021-02-01 00:14:03 2021-02-01 00:28:37          173   \n",
       "2      B00021          2021-02-01 00:27:48 2021-02-01 00:35:45           82   \n",
       "3               B00037 2021-02-01 00:12:50 2021-02-01 00:26:38           -1   \n",
       "4               B00037 2021-02-01 00:00:37 2021-02-01 00:09:35           -1   \n",
       "\n",
       "  DOlocationID SR_Flag Affiliated_base_number   duration  \n",
       "0           82    None        B00021           10.666667  \n",
       "1           56    None        B00021           14.566667  \n",
       "2          129    None        B00021            7.950000  \n",
       "3          225    None                 B00037  13.800000  \n",
       "4           61    None                 B00037   8.966667  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0220ac9-debb-45e1-9fdf-318a781d80ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:The average duration of the trip in the validation dataset is : 16.86 minutes\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"The average duration of the trip in the validation dataset is : {val_dataset['duration'].mean():.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2f5d8-06ab-4b38-8ace-7eb292545d39",
   "metadata": {},
   "source": [
    "We will now validate the results using the existing linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c8a9ef8-6d62-4220-9981-1fb16336f135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the columns to use for categorical variables\n",
    "pickup_id_colname = \"PUlocationID\"\n",
    "dropoff_id_colname = \"DOlocationID\"\n",
    "categorical_cols = [pickup_id_colname, dropoff_id_colname]\n",
    "\n",
    "# Vectorizing the data\n",
    "val_dicts = val_dataset[categorical_cols].to_dict(orient=\"records\")\n",
    "\n",
    "# Creating the `X` and `y` variables for the validation dataset\n",
    "X_val = dv.transform(val_dicts)\n",
    "y_val = val_dataset[\"duration\"].values\n",
    "\n",
    "# Computing the predictions of the trip duration using the validation dataset\n",
    "y_pred_val = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ebe16-d6f7-46d2-a4bd-fd0915a22572",
   "metadata": {},
   "source": [
    "Finally, we can look at the `RMSE` for the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a51034e6-4fc6-4377-b17b-98a8d504acc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:The RMSE of the validation dataset is: 12.85\n"
     ]
    }
   ],
   "source": [
    "rmse_val = mean_squared_error(y_true=y_val, y_pred=y_pred_val, squared=False)\n",
    "logger.info(f\"The RMSE of the validation dataset is: {rmse_val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e231f4b-d8af-48dc-af43-8e2350f119bc",
   "metadata": {},
   "source": [
    "## Final words\n",
    "\n",
    "In the previous sections, we saw the `RMSE` for the training dataset was around `10.53`, while the\n",
    "`RMSE` using the validation dataset was `12.85`. This shows that the model does perform a little\n",
    "worse in the validation dataset than the training dataset.\n",
    "\n",
    "However, this model is good enough for demostration purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
